{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24945f9",
   "metadata": {},
   "source": [
    "# Trabalho da 'turma de DM' - Data Mining do curso 'BI MASTER 2020-2'\n",
    "Estudo de caso: Previsão de vendas de produtos específico em uma empresa varejista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e24ba-5cde-4577-964a-df7903ec423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamamos o método 'set' do seaborn para ajustar os valores padrão de exibição dos gráficos\n",
    "sns.set_theme()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3c028-6ca1-4bb0-a8d7-223066c1dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais \"constantes\" apontando para os conjuntos de dados\n",
    "PATH_DATASET=\"base\"\n",
    "PATH_DATASET_PRODUTO=os.path.join(PATH_DATASET,\"BaseProduto.csv\")\n",
    "PATH_DATASET_VENDA=os.path.join(PATH_DATASET,\"BaseVenda.csv\")\n",
    "PATH_DATASET_LOJA=os.path.join(PATH_DATASET,\"BaseLoja.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327def7",
   "metadata": {},
   "source": [
    "## Carga dos conjuntos de dados: 'vendas', 'lojas' e 'produtos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841ae6c-3cfd-49d9-bc08-27ea44c3271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_venda = pd.read_csv(PATH_DATASET_VENDA, delimiter='|', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bf8d7-8806-493f-a287-d1bd7ea135cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_loja = pd.read_csv(PATH_DATASET_LOJA, delimiter='|', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c4cdc-0a50-46f8-ad22-d67d201fe33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df_produto = pd.read_csv(PATH_DATASET_PRODUTO, delimiter='|', encoding='cp1252', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6fead-cd46-4d06-ba17-f97adc7b75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d8de6-af9d-43e3-8efa-d522fb7b63cd",
   "metadata": {},
   "source": [
    "##### Filtramos o conjunto de dados para obter apenas calçados femininos vendidos no Rio de Janeiro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado = df_venda[(df_venda.SECAO == 'CALCADOS') & \n",
    "                              (df_venda.GRUPO == 'FEMININO') &\n",
    "                              (df_venda.CIDADE == 'RIO DE JANEIRO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99b084-2c79-435f-b742-462c3923fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_venda.shape)\n",
    "print(df_venda_preparado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_dados_selec_orig = (df_venda_preparado.shape[0] / df_venda.shape[0]) * 100\n",
    "print(f'Percentual de dados selecionados: {perc_dados_selec_orig:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc671b-7c16-4e34-9421-e053aa4cf7bc",
   "metadata": {},
   "source": [
    "##### Removemos colunas desnecessárias ao processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea230ba-04bc-40b9-83f4-45ad29f8a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado = df_venda_preparado.drop(['NumeroBoleta', \n",
    "                                              'Loja', \n",
    "                                              'UF', \n",
    "                                              'CIDADE',\n",
    "                                              'BAIRRO', \n",
    "                                              'Produto_Codigo', \n",
    "                                              'SECAO', \n",
    "                                              'GRUPO', \n",
    "                                              'CATEGORIA', \n",
    "                                              'COR', \n",
    "                                              'TAMANHO', \n",
    "                                              'PrecoVenda', \n",
    "                                              'PrecoTransacao'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificamos se existem valores nulos nos dados\n",
    "df_venda_preparado.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651491a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# número de registros antes da aglutinação\n",
    "qtd_dados_venda_preparado_antes = df_venda_preparado.shape[0]\n",
    "\n",
    "# aglutinamos (somando) os dados que ocorrem na mesma CriacaoReferencia\n",
    "df_venda_preparado = df_venda_preparado.groupby(by=['CriacaoReferencia'], as_index=False)['Quantidade'].sum()\n",
    "\n",
    "# número de registros depois da aglutinação\n",
    "qtd_dados_venda_preparado_depois = df_venda_preparado.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_reducao_dados_aglutinados = (1 - (qtd_dados_venda_preparado_depois / qtd_dados_venda_preparado_antes)) * 100\n",
    "print(f'Percentual de redução do número de registros via aglutinação: {perc_reducao_dados_aglutinados:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e894d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatos padronizados para as datas\n",
    "fmt_dt_iso='%Y-%m-%d'\n",
    "fmt_dt_ano_mes='%Y-%m'\n",
    "fmt_dt_ano_mes_semana='%Y-%m-%W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares para calcular as janelas de tempo\n",
    "f_data_menos_uma_semana   = lambda d: d + relativedelta(weeks=-1)\n",
    "f_data_menos_duas_semanas = lambda d: d + relativedelta(weeks=-2)\n",
    "f_data_menos_um_ano       = lambda d: d + relativedelta(years=-1)\n",
    "\n",
    "def formatar_data(df, coluna, formato):\n",
    "    \"\"\"Aplica um formato de data em uma coluna de um dataframe e a retorna.\"\"\"\n",
    "    return df[coluna].dt.strftime(formato)\n",
    "\n",
    "def aplicar_funcoes(df, colunas_e_funcoes):\n",
    "    \"\"\"Percorre as tuplas de 'colunas_e_funcoes' e, para cada dicionario nela contidos, faz:\n",
    "    - aplica a 'funcao' na coluna 'col_org', gravando o resultado na coluna 'col_dst' do dataframe 'df'\n",
    "    \"\"\"\n",
    "    for e in colunas_e_funcoes:\n",
    "        col_dst = e['col_dst']\n",
    "        col_org = e['col_org']\n",
    "        f_offset_data = e['funcao']\n",
    "                \n",
    "        # aplica a funcao 'f_offset_data' na coluna 'col_org' e \n",
    "        # salva o resultado na coluna 'col_dst'\n",
    "        df[col_dst] = df[col_org].map(f_offset_data)\n",
    "    \n",
    "def aplicar_formatos_data(df, colunas_e_formatos):\n",
    "    \"\"\"Percorre as tuplas de 'colunas_e_formatos' e, para cada dicionario nela contidos, faz:\n",
    "    - aplica o 'fmt_data' na coluna 'col_org', gravando o resultado na coluna 'col_dst' do dataframe 'df'\n",
    "    \"\"\"\n",
    "    for e in colunas_e_formatos:\n",
    "        col_dst = e['col_dst']\n",
    "        col_org = e['col_org']\n",
    "        fmt_data = e['fmt_data']\n",
    "        \n",
    "        # aplica o formato de data 'fmt_data' na coluna 'col_org' e \n",
    "        # salva o resultado na coluna 'col_dst'\n",
    "        df[col_dst] = formatar_data(df, col_org, fmt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81815d2-049a-4209-899e-9b6a6e2abdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos uma coluna temporária de data da venda no padrão ISO\n",
    "%time df_venda_preparado['DataVenda'] = pd.to_datetime(df_venda_preparado['CriacaoReferencia'],format=fmt_dt_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos uma coluna de ano-mês para facilitar as aglutinações dos dados\n",
    "%time df_venda_preparado['AnoMes'] =  formatar_data(df_venda_preparado, 'DataVenda', fmt_dt_ano_mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bfe8a-c03a-4fc5-af9f-7725fee7566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos colunas temporárias no dataframe para armazenar as datas de interesse\n",
    "# essas colunas serão formatadas na sequência\n",
    "\n",
    "# col_dst recebe funcao aplicada em col_org, na ordem das tuplas\n",
    "colunas_e_offsets_de_tempo = (\n",
    "    {'col_dst':'Data1SemanaAnterior',    'col_org': 'DataVenda',       'funcao': f_data_menos_uma_semana},\n",
    "    {'col_dst':'Data2SemanaAnterior',    'col_org': 'DataVenda',       'funcao': f_data_menos_duas_semanas},\n",
    "    {'col_dst':'DataAnoAnterior',        'col_org': 'DataVenda',       'funcao': f_data_menos_um_ano},\n",
    "    {'col_dst':'DataAnoAnterior1Semana', 'col_org': 'DataAnoAnterior', 'funcao': f_data_menos_uma_semana},\n",
    "    {'col_dst':'DataAnoAnterior2Semana', 'col_org': 'DataAnoAnterior', 'funcao': f_data_menos_duas_semanas}\n",
    ")\n",
    "\n",
    "# aplicamos as funções, medindo o tempo (demora bastante)\n",
    "%time aplicar_funcoes(df_venda_preparado, colunas_e_offsets_de_tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55aa829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0965ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criamos colunas de datas específicas (formatadas) no dataframe para auxiliar a geração das janelas de\n",
    "# tempo para o processamento dos algoritmos de regressão\n",
    "\n",
    "# col_dst recebe formato de data aplicado em col_org, na ordem das tuplas\n",
    "colunas_e_formatos = (\n",
    "    {'col_dst':'AnoMesSemana',                   'col_org': 'DataVenda',              'fmt_data': fmt_dt_ano_mes_semana},\n",
    "    {'col_dst':'AnoMesSemana1SemanaAnterior',    'col_org': 'Data1SemanaAnterior',    'fmt_data': fmt_dt_ano_mes_semana},\n",
    "    {'col_dst':'AnoMesSemana2SemanaAnterior',    'col_org': 'Data2SemanaAnterior',    'fmt_data': fmt_dt_ano_mes_semana},\n",
    "    {'col_dst':'AnoMesSemanaAnoAnterior',        'col_org': 'DataAnoAnterior',        'fmt_data': fmt_dt_ano_mes_semana},\n",
    "    {'col_dst':'AnoMesSemanaAnoAnterior1Semana', 'col_org': 'DataAnoAnterior1Semana', 'fmt_data': fmt_dt_ano_mes_semana},\n",
    "    {'col_dst':'AnoMesSemanaAnoAnterior2Semana', 'col_org': 'DataAnoAnterior2Semana', 'fmt_data': fmt_dt_ano_mes_semana}\n",
    ")\n",
    "\n",
    "# aplicamos os formatos, medindo o tempo (demora bastante)\n",
    "%time aplicar_formatos_data(df_venda_preparado, colunas_e_formatos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca567c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removemos, do dataframe, as colunas que não são mais necessárias para processamento posterior\n",
    "colunas_a_remover = ['CriacaoReferencia',\n",
    "                     'DataVenda',\n",
    "                     'Data1SemanaAnterior',\n",
    "                     'Data2SemanaAnterior',\n",
    "                     'DataAnoAnterior',\n",
    "                     'DataAnoAnterior1Semana',\n",
    "                     'DataAnoAnterior2Semana']\n",
    "\n",
    "%time df_venda_preparado.drop(colunas_a_remover, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_preparado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66111010-65b8-4646-b363-97a95c7b5edc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c86894-6c0a-411d-ad22-a629ed157210",
   "metadata": {},
   "source": [
    "### Análise Estatística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4c1eb-430e-40ee-8441-1b866e5b5f3f",
   "metadata": {},
   "source": [
    "#### Grafico da série temporal e da Autocorrelação - Mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f7dc7-81a9-4f8c-a4cf-ff38161c592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_agrupado_mes = df_venda_preparado.groupby(by=['AnoMes'], as_index=False)['Quantidade'].sum()\n",
    "df_venda_agrupado_mes = df_venda_agrupado_mes.sort_values(['AnoMes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258a255-0581-47d3-8749-43cef085fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = sns.color_palette(\"deep\",8)[2]\n",
    "blue = sns.color_palette(\"deep\",8)[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "df_venda_agrupado_mes.plot(x=\"AnoMes\",y=\"Quantidade\",color=\"g\", fontsize=15, ax=ax)\n",
    "plt.xlabel(\"Ano/Mês\",fontsize=15)\n",
    "plt.title(\"Quantidade de Itens Vendidos por Mês/Ano\", fontsize=15)\n",
    "plt.ylabel(\"Quantidade Vendida\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plot_acf(df_venda_agrupado_mes.Quantidade, ax=ax)\n",
    "plt.title(\"Auto Correlação\", fontsize=15)\n",
    "plt.xlabel(\"Lag\",fontsize=15)\n",
    "plt.ylabel(\"Correlação\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16448703-d699-4386-943b-743daa2d1ba5",
   "metadata": {},
   "source": [
    "#### Grafico da série temporal e da Autocorrelação - Semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf067b7-5cbc-4238-b2cf-c7a4b8fdc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_agrupado_semana = df_venda_preparado.groupby(by=['AnoMesSemana'], as_index=False)['Quantidade'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dddde2-b498-4b82-b90a-23f514983790",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = sns.color_palette(\"deep\",8)[2]\n",
    "blue = sns.color_palette(\"deep\",8)[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "df_venda_agrupado_semana.plot(x=\"AnoMesSemana\",y=\"Quantidade\",color=\"g\", fontsize=15, ax=ax)\n",
    "plt.xlabel(\"Ano/Mês/Semana\",fontsize=15)\n",
    "plt.title(\"Quantidade de Itens Vendidos por Mês/Ano/Semana\", fontsize=15)\n",
    "plt.ylabel(\"Quantidade Vendida\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "plot_acf(df_venda_agrupado_semana.Quantidade, ax=ax)\n",
    "plt.title(\"Auto Correlação\", fontsize=15)\n",
    "plt.xlabel(\"Lag\",fontsize=15)\n",
    "plt.ylabel(\"Correlação\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e91c06-887f-4726-a373-e2c740a19573",
   "metadata": {},
   "source": [
    "### Previsões Estatísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9ec8e-aaec-4e1a-bcf5-90f599595ee2",
   "metadata": {},
   "source": [
    "#### Média Móvel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f13e-46af-498b-82c4-0d1ea6256b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n",
    "\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    \n",
    "    plt.figure(figsize=(17,8))\n",
    "    plt.title('Moving average\\n window size = {}'.format(window))\n",
    "    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n",
    "    \n",
    "    #Plot confidence intervals for smoothed values\n",
    "    if plot_intervals:\n",
    "        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n",
    "        deviation = np.std(series[window:] - rolling_mean[window:])\n",
    "        lower_bound = rolling_mean - (mae + scale * deviation)\n",
    "        upper_bound = rolling_mean + (mae + scale * deviation)\n",
    "        plt.plot(upper_bound, 'r--', label='Upper bound / Lower bound')\n",
    "        plt.plot(lower_bound, 'r--')\n",
    "            \n",
    "    plt.plot(series[window:], label='Actual values')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cf601-bb5d-4bba-8971-fb785be9e52e",
   "metadata": {},
   "source": [
    "#### Média Móvel com janelas para agrupamento mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca8c2a-590b-41bf-aa89-03beb8a3018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_average(df_venda_agrupado_mes.Quantidade, 5)\n",
    "plot_moving_average(df_venda_agrupado_mes.Quantidade, 10)\n",
    "plot_moving_average(df_venda_agrupado_mes.Quantidade, 12, plot_intervals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8273b-84a1-4a88-a121-678cd06a8965",
   "metadata": {},
   "source": [
    "#### Média Móvel com janelas para agrupamento Semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a00715-2562-462f-93c4-1d65f90ad591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_moving_average(df_venda_agrupado_semana.Quantidade, 2)\n",
    "plot_moving_average(df_venda_agrupado_semana.Quantidade, 5)\n",
    "plot_moving_average(df_venda_agrupado_mes.Quantidade, 11, plot_intervals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f1e7d-354f-4843-81cf-a2a00eeb4107",
   "metadata": {},
   "source": [
    "### Amortecimento Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c191c0-fb23-4768-95b8-1e1a956c419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result\n",
    "  \n",
    "def plot_exponential_smoothing(series, alphas):\n",
    " \n",
    "    plt.figure(figsize=(17, 8))\n",
    "    for alpha in alphas:\n",
    "        plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n",
    "    plt.plot(series.values, \"c\", label = \"Actual\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.axis('tight')\n",
    "    plt.title(\"Exponential Smoothing\")\n",
    "    plt.grid(True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ef9d4-9a28-4a02-a5e9-741358e10c7e",
   "metadata": {},
   "source": [
    "#### Mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc9a04-fe47-4411-b10c-9c8ff61994b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exponential_smoothing(df_venda_agrupado_mes.Quantidade, [0.05, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e348ef-3a3d-4f13-8770-eaa90cfad268",
   "metadata": {},
   "source": [
    "#### Semanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619bfef-2da6-4cda-a42b-f973290b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exponential_smoothing(df_venda_agrupado_semana.Quantidade, [0.05, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1576ad-c797-4c91-abe5-9d433e215d88",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066166df-4486-4242-abf3-8264007e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_venda_agrupado_semana[\"Quantidade\"].values\n",
    "\n",
    "split = int(0.8*len(X))\n",
    "train, test = X[0:split], X[split:]\n",
    "\n",
    "history = [x for x in train]\n",
    "predictions = []\n",
    "for t in range(len(test)):\n",
    "\tmodel = ARIMA(history, order=(5,1,0))\n",
    "\tmodel_fit = model.fit()\n",
    "\toutput = model_fit.forecast()\n",
    "\tyhat = output[0]\n",
    "\tpredictions.append(yhat)\n",
    "    \n",
    "\tobs = test[t]\n",
    "\thistory.append(obs)\n",
    "mse = mean_squared_error(test, predictions)\n",
    "\n",
    "print(f\"MSE error: {mse}\")\n",
    "\n",
    "plt.figure(figsize=(17,8))\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.title(\"ARIMA fit to Sales Data\",fontsize=15)\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1ab1c-5bf2-4401-b2cc-d85de3712d00",
   "metadata": {},
   "source": [
    "## Previsões Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11f8c3-01e3-4626-b913-0b82ecb6c3f2",
   "metadata": {},
   "source": [
    "#### Todas as vendas realizadas agrupadas por semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a623dc-2608-45f1-b979-9697a1edcb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venda_historico_agrupado = df_venda_preparado.groupby(by=['AnoMesSemana'], as_index=False)['Quantidade'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46588721-f50a-4b9d-82e3-8e17e74b4dc7",
   "metadata": {},
   "source": [
    "#### Métricas de Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307caa5-a3fd-4afc-b97d-76e9c4c495d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_metricas_erro(y_pred,y_test, number_features):\n",
    "    rmse = math.sqrt(mean_squared_error(y_pred,y_test))\n",
    "    print('RMSE: ', rmse)\n",
    "    \n",
    "    mse = mean_squared_error(y_pred,y_test)\n",
    "    print('MSE: ',mse)    \n",
    "    \n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    print('MAPE: ',mape, '%')\n",
    "    \n",
    "    r2 = r2_score(y_pred,y_test)\n",
    "    print('R2 Score: ', r2)\n",
    "    \n",
    "    if (number_features is not None and number_features > 0): \n",
    "        number_samples = len(y_pred)\n",
    "        adj_r2_score = 1-(1-r2)*(number_samples-1)/(number_samples-number_features-1)\n",
    "        print('R2 Ajustado: ', adj_r2_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba747f-fa24-411c-adfa-c8de72531a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra_grafico_previsao(y_pred, y_test):\n",
    "    plt.plot(y_pred, label='previsto', marker='o')\n",
    "    plt.plot(y_test, label='real', marker='+')\n",
    "    plt.ylabel(\"Venda\")\n",
    "    plt.title(\"Previsão x Vendas\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301a7ee-fec6-4f25-8ece-7947bc0ba6fa",
   "metadata": {},
   "source": [
    "#### Montagem dos diferentes datasets para treino "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18dde2-1da9-4ead-ae24-af6feede2b5a",
   "metadata": {},
   "source": [
    "##### Dados da série histórica com a janela informada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1b925-3eac-4a59-9ce7-001465a9b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_dataset_por_janela(dataset=None, window=12):\n",
    "    dataSize = len(dataset)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(window, dataSize):\n",
    "        X.append(dataset.iloc[i-window:i, 1])\n",
    "        y.append(dataset.iloc[i, 1])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c75927-047e-4c52-8128-c8da78906ce7",
   "metadata": {},
   "source": [
    "##### Penúltima e antepenúltima semana/ mesma semana do ano anterior / penúltima e antepenúltima semana do ano anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79127234-87f1-49c1-9af4-47d3be07f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_dataset_ano_anterior(dataset):\n",
    "    df_venda_ml = dataset[dataset.AnoMesSemana >= '2020-01-02'].sort_values(['AnoMesSemana'])\n",
    "    df_venda_agrupado_ml = df_venda_ml.groupby('AnoMesSemana', as_index=False).agg({\n",
    "        'Quantidade':'sum',\n",
    "        'AnoMesSemana1SemanaAnterior': 'max',\n",
    "        'AnoMesSemana2SemanaAnterior': 'max',\n",
    "        'AnoMesSemanaAnoAnterior': 'max',\n",
    "        'AnoMesSemanaAnoAnterior1Semana':'max',\n",
    "        'AnoMesSemanaAnoAnterior2Semana':'max'})\n",
    "    \n",
    "    df_venda_ml_final = pd.merge(df_venda_agrupado_ml, df_venda_historico_agrupado, left_on=\"AnoMesSemanaAnoAnterior\", right_on=\"AnoMesSemana\", suffixes=(\"\",\"_AnoAnterior\"))\n",
    "\n",
    "    df_venda_ml_final = pd.merge(df_venda_ml_final, df_venda_historico_agrupado, left_on=\"AnoMesSemanaAnoAnterior1Semana\", right_on=\"AnoMesSemana\", suffixes=(\"\",\"_AnoAnterior1Semana\"))\n",
    "    df_venda_ml_final = pd.merge(df_venda_ml_final, df_venda_historico_agrupado, left_on=\"AnoMesSemanaAnoAnterior2Semana\", right_on=\"AnoMesSemana\", suffixes=(\"\",\"_AnoAnterior2Semana\"))\n",
    "    df_venda_ml_final = pd.merge(df_venda_ml_final, df_venda_historico_agrupado, left_on=\"AnoMesSemana1SemanaAnterior\", right_on=\"AnoMesSemana\", suffixes=(\"\",\"_1SemanaAnterior\"))\n",
    "    df_venda_ml_final = pd.merge(df_venda_ml_final, df_venda_historico_agrupado, left_on=\"AnoMesSemana2SemanaAnterior\", right_on=\"AnoMesSemana\", suffixes=(\"\",\"_2SemanaAnterior\"))\n",
    "    \n",
    "    df_venda_ml_final = df_venda_ml_final[['AnoMesSemana','Quantidade_1SemanaAnterior','Quantidade_2SemanaAnterior','Quantidade_AnoAnterior','Quantidade_AnoAnterior1Semana','Quantidade_AnoAnterior2Semana','Quantidade']]\n",
    "    \n",
    "    np_dataset =  df_venda_ml_final.to_numpy()\n",
    "    X = np_dataset[:,1:-1]\n",
    "    y = np_dataset[:,-1]\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44493dfd-154f-443f-8e68-eb493b7e4184",
   "metadata": {},
   "source": [
    "##### Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_with_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    calcula_metricas_erro(y_pred=y_pred, y_test=y_test, number_features=X_test.shape[1])\n",
    "    mostra_grafico_previsao(y_pred=y_pred, y_test=y_test)\n",
    "    \n",
    "    # imprimimos os parametros usados no modelo, caso tenha sido usado o GridSearchCV\n",
    "    # para determinar um modelo.\n",
    "    try:\n",
    "        print(model.best_params_)\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuned_random_forest_regressor():\n",
    "    # veja os parâmetros em:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    tuned_parameters = {\n",
    "        'n_estimators': [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'criterion': ['mse', 'mae'],\n",
    "        'max_depth': [None, 1, 2, 4, 6, 8],\n",
    "        'min_samples_leaf': [x for x in range(1,12,2)], # de 1 a 11 de 2 em 2\n",
    "        'random_state': [0], # para facilitar a reprodução dos resultados observados\n",
    "        'n_jobs': [-1] # usamos todos os processadores lógicos disponíveis no treino e na predição do modelo\n",
    "    }\n",
    "    \n",
    "    # com o RandomForestRegressor, não podemos usar o scoring do GridSearchCV\n",
    "    return GridSearchCV(RandomForestRegressor(), tuned_parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b63f6-5486-436f-81c2-1522a03f04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_random_forest(X_train, X_test, y_train, y_test, best_model=True):\n",
    "    if best_model:\n",
    "        regressor = create_tuned_random_forest_regressor()\n",
    "    else:\n",
    "        regressor = RandomForestRegressor(n_estimators = 10, random_state=0)\n",
    "\n",
    "    train_predict_with_model(X_train, X_test, y_train, y_test, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c565db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuned_svm():\n",
    "    # veja os parâmetros em:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "    tuned_parameters = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "        'tol': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "        'C': list(np.arange(1.0, 16.0, 2.0)), # C de 1 a 16 de 2 em 2\n",
    "        'epsilon': [0.1, 1e-2, 1e-3]\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(svm.SVR(), tuned_parameters, verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47412ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_svm(X_train, X_test, y_train, y_test, best_model=True):\n",
    "    # veja os parâmetros em:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "    if best_model:\n",
    "        regressor = create_tuned_svm()\n",
    "    else:\n",
    "        regressor = svm.SVR(kernel='linear', C=15.0)\n",
    "\n",
    "    train_predict_with_model(X_train, X_test, y_train, y_test, regressor)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594518ee-3f9d-4ba7-95ae-30527c3f8ff4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45bedc-a6e4-4d50-b348-db16023023c3",
   "metadata": {},
   "source": [
    "### Treino e Teste dos Modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250d1bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# funções geradoras dos conjuntos de dados de cada cenário que iremos analisar\n",
    "f_gerar_ano_anterior_e_corrente = lambda: monta_dataset_ano_anterior(dataset=df_venda_preparado)\n",
    "f_gerar_4_semanas               = lambda: monta_dataset_por_janela(dataset=df_venda_historico_agrupado, window=4)\n",
    "f_gerar_12_semanas              = lambda: monta_dataset_por_janela(dataset=df_venda_historico_agrupado, window=12)\n",
    "f_gerar_24_semanas              = lambda: monta_dataset_por_janela(dataset=df_venda_historico_agrupado, window=24)\n",
    "f_gerar_36_semanas              = lambda: monta_dataset_por_janela(dataset=df_venda_historico_agrupado, window=36)\n",
    "f_gerar_52_semanas              = lambda: monta_dataset_por_janela(dataset=df_venda_historico_agrupado, window=52)\n",
    "\n",
    "# um iterável ordenado de dicionários, contendo os nomes dos cenários e um lambda para gerar\n",
    "# o conjunto de dados (evitamos incluir os dados no dicionário para não aumentar o footprint \n",
    "# de memória)\n",
    "cenarios_analise_ml = (\n",
    "    { 'nome':'ano anterior e corrente', 'f_gerar_dataset': f_gerar_ano_anterior_e_corrente},\n",
    "    { 'nome':'janela de 4 semanas',     'f_gerar_dataset': f_gerar_4_semanas},\n",
    "    { 'nome':'janela de 12 semanas',    'f_gerar_dataset': f_gerar_12_semanas},\n",
    "    { 'nome':'janela de 24 semanas',    'f_gerar_dataset': f_gerar_24_semanas},\n",
    "    { 'nome':'janela de 36 semanas',    'f_gerar_dataset': f_gerar_36_semanas},\n",
    "    { 'nome':'janela de 52 semanas',    'f_gerar_dataset': f_gerar_52_semanas}\n",
    ")\n",
    "\n",
    "algoritmos_ml = (\n",
    "    { 'nome': 'Random Forest', 'f_train_predict': train_predict_random_forest},\n",
    "    { 'nome': 'SVM'          , 'f_train_predict': train_predict_svm}\n",
    ")\n",
    "\n",
    "# percorremos os cenários, treinando os algoritmos de IA e fazendo previsões nos dados\n",
    "# cenários x algorítmos (com e sem otimização de hiper-parâmetros)\n",
    "for idx, cenario in enumerate(cenarios_analise_ml):\n",
    "    nome_cenario = cenario['nome']\n",
    "    f_gerar_dataset = cenario['f_gerar_dataset']\n",
    "    X_train, X_test, y_train, y_test = f_gerar_dataset() # aqui, chamamos a função lambda para obter os dados do cenário\n",
    "    \n",
    "    print(f'Cenário {idx + 1}: {nome_cenario}' + os.linesep)\n",
    "    \n",
    "    for alg in algoritmos_ml:\n",
    "        nome_alg = alg['nome']\n",
    "        f_train_predict = alg['f_train_predict']\n",
    "        \n",
    "        for best_model in (False, True):\n",
    "            s_best_model = 'melhores' if best_model else 'padrão'\n",
    "            \n",
    "            print(f'Algorítmo: {nome_alg}')\n",
    "            print(f'Parâmetros do modelo: {s_best_model}.' + os.linesep)\n",
    "            \n",
    "            %time f_train_predict(X_train, X_test, y_train, y_test, best_model)\n",
    "            print()\n",
    "    \n",
    "    print(('-' * 50) + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa68e1-0098-4094-95a6-04cc4dd09166",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
